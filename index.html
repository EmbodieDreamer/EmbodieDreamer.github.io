<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="EmbodieDreamer: Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling">
  <meta name="keywords" content="EmbodieDreamer">
  <!-- <meta name="google-site-verification" content="ciQsol-i_rwd2kkpVI_G-EFX4g72KA2HF-cDUi52lIo" /> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/images/teaser.pdf"/> -->
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <title>EmbodieDreamer: Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/motion.png"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">EmbodieDreamer: Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling</h1>
            <!-- <h1 class="title is-2 publication-title"><strong><span style="color:#5e7dbd";>MotionStreamer</span></strong>: <span style="color:#EE822F";>Streaming Motion Generation </span> <br> via <span style="color:#069b1c";>Diffusion-based Autoregressive Model</span> <br> in <span style="color:#a50c07";>Causal Latent Space</span></h1> -->
            <!-- <span style="color: rgb(219, 13, 78); font-size: 1.2em;">Arxiv2025</span> -->
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=Wp7sUlIAAAAJ&hl=en" target="_blank">Boyuan Wang<sup>1,2*</sup></a>,&nbsp</span>
              <span class="author-block">
                <a href="" target="_blank">Xinpan Meng<sup>1,2*</sup></a>,&nbsp</span>
              <span class="author-block">
                <a href="https://jeffwang987.github.io/" target="_blank">Xiaofeng Wang<sup>1,2*</sup></a>,&nbsp</span>
              <span class="author-block">
                <a href="http://www.zhengzhu.net/" target="_blank">Zheng Zhu<sup>1*</sup></a>,&nbsp</span>
              <span class="author-block">
                <a href="" target="_blank">Angen Ye<sup>1,2</sup></a>,&nbsp</span>
              <span class="author-block">
                <a href="" target="_blank">Yang Wang<sup>1</sup></a>,&nbsp</span>
              <br>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=DSjGPu0AAAAJ" target="_blank">Zhiqin Yang<sup>1</sup></a>,&nbsp</span>
              <span class="author-block">
                <a href="" target="_blank">Chaojun Ni<sup>1,3</sup></a>,&nbsp</span>
              <span class="author-block">
                <a href="" target="_blank">Guan Huang<sup>1</sup></a>,&nbsp</span>
                
                <span class="author-block">
                <a href="" target="_blank">Xingang Wang<sup>2</sup></a></span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block" style="margin-right: 20px;"><sup>1</sup> GigaAI </span>
                    <span class="author-block" style="margin-right: 20px;"><sup>2</sup> Institute of Automation, Chinese Academy of Sciences, China </span>
                    <!-- <span class="author-block" style="margin-right: 20px;"><sup>3</sup> Luoyang Institute for Robot and Intelligent Equipment, China </span> -->
                    <!-- <span class="author-block" style="margin-right: 20px;"><sup>4</sup> GigaAI, China </span> -->
                    <span class="author-block" style="margin-right: 20px;"><sup>3</sup> Peking University, China </span>
                    <!-- <span class="author-block" style="margin-right: 20px;"><sup>6</sup> The Chinese University of Hong Kong </span> -->

                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links" style="display: flex; justify-content: center; align-items: center; gap: 10px;">
                      <!-- ArXiv abstract Link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/" class="external-link button is-normal is-rounded is-dark" target="_blank">               
                          <span class="icon">
                            <i class="ai ai-arxiv"></i>
                          </span>
                          <span>arXiv</span>
                        </a>
                      </span>
                      
                      <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/" class="external-link button is-normal is-rounded is-dark" target="_blank">
                          <span class="icon">
                            <i class="fas fa-file-pdf"></i>
                          </span>
                          <span>Paper</span>
                        </a>
                      </span>

                      <!-- Github link -->
                      <!-- <span class="link-block" style="display: flex; align-items: center; gap: 10px;"> -->
                        <!-- <a href="https://github.com/GigaAI-research/HumanDreamer" class="external-link button is-normal is-rounded is-dark" target="_blank">
                          <span class="icon">
                            <i class="fab fa-github"></i>
                          </span>
                          <span>GitHub</span>
                        </a> -->
                        <!-- <a href="https://github.com/GigaAI-research/HumanDreamer" target="_blank" class="github-badge" style="background: #24292e; color: white; padding: 5px 10px; border-radius: 15px; text-decoration: none; font-size: 0.9em; display: flex; align-items: center; gap: 5px;">
                          <i class="fas fa-star" style="color: #f1e05a;"></i>
                          <span class="github-stars"></span>
                        </a> -->
                      <!-- </span> -->

                      <span class="link-block">
                        <a href="https://github.com/GigaAI-research/EmbodieDreamer" class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                            <i class="fab fa-github"></i>
                          </span>
                          <span>Code (Coming Soon)</span>
                        </a>
                      </span>
                      <!-- <span class="link-block">
                        <a href="https://github.com/GigaAI-research/HumanDreamer" class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                            <i class="fab fa-github"></i>
                          </span>
                          <span>Datset (Coming Soon)</span>
                        </a>
                      </span> -->
                    </div>
                  </div>
          </div>
        </div>
      </div>
    </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <img src="static/images/main_demo.png" width="90%" style="max-height: 350px;" alt="teaser">
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero ">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The rapid advancement of Embodied AI has led to an increasing demand for large-scale, high-quality real-world data. However, collecting such embodied data remains costly and inefficient. 
            As a result, simulation environments have become a crucial surrogate for training robot policies. 
            Yet, the significant Real2Sim2Real gap remains a critical bottleneck, particularly in terms of physical dynamics and visual appearance. 
            To address this challenge, we propose EmbodieDreamer, a novel framework that reduces the Real2Sim2Real gap from both the physics and appearance perspectives. 
            Specifically, we propose PhysAligner, a differentiable physics module designed to reduce the Real2Sim physical gap. 
            It jointly optimizes robot-specific parameters such as control gains and friction coefficients to better align simulated dynamics with real-world observations. 
            In addition, we introduce VisAligner, which incorporates a conditional video diffusion model to bridge the Sim2Real appearance gap by translating low-fidelity simulated renderings into photorealistic videos conditioned on simulation states, enabling high-fidelity visual transfer. 
            Extensive experiments validate the effectiveness of EmbodieDreamer. The proposed PhysAligner reduces physical parameter estimation error by 3.74% compared to simulated annealing methods while improving optimization speed by 89.91%. 
            Moreover, using the generated photorealistic environment for robot policy learning significantly improves the real-world task success rate by 29.17%. Code, model and data will be publicly available.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Paper method -->
<section class="section hero">
  <div class="container">
    <h2 class="title is-3 has-text-centered">Method Overview</h2>
    
    <!-- PhysAligner 部分 -->
    <div style="margin-bottom: 40px;">
      <h3 class="title is-4 has-text-centered">PhysAligner</h3>
      <div style="display: flex; flex-direction: column; align-items: center; width: 90%; margin: 0 auto;">
        <img src="static/images/PhysAligner.png" style="width: 100%; max-height: 350px; object-fit: contain; margin-bottom: 2px;">
        <p style="margin-bottom: 20px; width: 100%; font-size: 0.9em; text-align: justify;">
          The figure illustrates the workflow of PhysAligner. First, a large amount of data is generated using a simulator. Then, a surrogate model is trained to fit the data. Finally, the physical parameters are optimized through gradient descent.
        </p>
        <video autoplay controls muted loop style="width: 100%; height: auto;">
          <source src="static/videos/compare_physaligner.mp4" type="video/mp4">
        </video>
      </div>
    </div>
    
    <!-- VisAligner 部分 -->
    <div style="margin-bottom: 40px;">
      <h3 class="title is-4 has-text-centered">VisAligner</h3>
      <div style="display: flex; flex-direction: column; align-items: center; width: 90%; margin: 0 auto;">
        <img src="static/images/VisAligner.png" style="width: 100%; max-height: 350px; object-fit: contain; margin-bottom: 2px;">
        <p style="margin-bottom: 20px; width: 100%; font-size: 0.9em; text-align: justify;">
          The framework of VisAligner. A reference image containing the initial background and robot appearance information serves as the first frame of the conditioned video. The subsequent frames are generated by performing pixel-wise addition of the robot's motion observations from the simulated environment and the segmentation masks of the foreground objects. These frames are then encoded into latents via a VAE encoder, concatenated with noise along the channel dimension, and input to VisAligner for denoising. Spatial-temporal attention mechanisms are employed to capture long-range dependencies across both spatial and temporal dimensions, thereby enhancing the coherence and visual quality of the generated video. The final video is obtained by decoding the denoised latents.
        </p>
        <video autoplay controls muted loop style="width: 100%; height: auto;">
          <source src="static/videos/compare_seg.mp4" type="video/mp4">
        </video>
      </div>
    </div>

  </div>

  <style>
    .carousel-container {
      position: relative;
      width: 80%;
      margin: 0 auto;
      overflow: hidden;
      
    }
    .video-carousel {
      display: flex;
      transition: transform 0.5s ease;
    }
    video {
      width: 100%;
      height: auto;
    }
    .carousel-button {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      background-color: rgba(0, 0, 0, 0.5);
      color: white;
      border: none;
      font-size: 2rem;
      padding: 10px;
      cursor: pointer;
    }
    .prev {
      left: 10px;
    }
    .next {
      right: 10px;
    }
  </style>

  <div class="carousel-container">
    <div class="video-carousel" id="carousel">
      <!-- Video elements will go here -->
    </div>
    <button class="carousel-button prev" onclick="moveCarousel(-1)">&#10094;</button>
    <button class="carousel-button next" onclick="moveCarousel(1)">&#10095;</button>
  </div>



</section>


 





<!-- BibTex citation -->
<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wang2025humandreamerx,
      title={HumanDreamer-X: Photorealistic Single-image Human Avatars Reconstruction via Gaussian Restoration}, 
      author={Boyuan Wang and Runqi Ouyang and Xiaofeng Wang and Zheng Zhu and Guosheng Zhao and Chaojun Ni and Guan Huang and Lihong Liu and Xingang Wang},
      journal={arXiv preprint arXiv:2504.03536},
      year={2025}
      }
  </code></pre>
  </div>
</section> -->
<!--End BibTex citation -->
  <script>
    // Video file names
    const videoFiles = [
      'static/videos/rt1_0.mp4', 'static/videos/rt1_1.mp4', 'static/videos/rt1_2.mp4', 'static/videos/rt1_3.mp4', 'static/videos/rt1_4.mp4', 'static/videos/rt1_5.mp4'
    ];

    let currentIndex = 0;

    // Function to create video elements
    function loadVideos() {
      const carousel = document.getElementById('carousel');
      carousel.innerHTML = ''; // Clear any existing content

      // Create video elements
      videoFiles.forEach((file, index) => {
        const videoElement = document.createElement('video');
        videoElement.src = file;
        videoElement.controls = true;
        videoElement.style.display = (index === currentIndex) ? 'block' : 'none'; // Show only the current video
        carousel.appendChild(videoElement);
      });
    }

    // Function to move the carousel
    function moveCarousel(direction) {
      currentIndex = (currentIndex + direction + videoFiles.length) % videoFiles.length; // Loop back to start or end
      loadVideos();
    }

    // Initialize the carousel
    loadVideos();
  </script>

<style>
@keyframes flowingArrow {
  0% {
    opacity: 0.4;
    transform: translateX(-3px);
  }
  50% {
    opacity: 1;
    transform: translateX(3px);
  }
  100% {
    opacity: 0.4;
    transform: translateX(-3px);
  }
}

.videobox {
  width: 100%;
  height: 100%;
  padding: 0;
  margin: 0;
  overflow: hidden;
  background-color: transparent;
}

.videobox video {
  width: 100%;
  height: 100%;
  object-fit: cover;
  display: block;
  background-color: transparent;
}

.fixed-height {
  height: 300px;
  border: none;
  overflow: hidden;
  background-color: transparent;
}

.fixed-height video {
  width: 100%;
  height: 100%;
  object-fit: contain;
  border: none;
  background-color: transparent;
}

video {
  border: none;
  outline: none;
  background-color: transparent;
}
</style>

<script>
// 添加到页面的script部分
fetch('https://api.github.com/repos/Li-xingXiao/272-dim-Motion-Representation')
  .then(response => response.json())
  .then(data => {
    document.querySelector('.github-stars').textContent = data.stargazers_count;
  });
</script>

</body>
</html>
